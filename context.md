# EXPLICACI√ìN: EDA vs PREPROCESAMIENTO

## ¬øCu√°l es la diferencia entre los 2 archivos?

### **ARCHIVO #1: `stroke_eda_complete.ipynb`**

**¬øQu√© es?** An√°lisis Exploratorio de Datos (EDA)

**¬øQu√© hace?**
-  ANALIZAR y ENTENDER el dataset original
-  Ver distribuciones, correlaciones, calidad de datos
-  Identificar patrones y problemas (desbalanceo)
-  Decidir QU√â hacer en el preprocesamiento

**Resultado:** Sabemos que:
- age es la variable M√ÅS importante (correlaci√≥n 0.246)
- Hay desbalanceo SEVERO: 19:1 (95% sin stroke, 5% con stroke)
- gender y Residence_type NO sirven (correlaci√≥n 0.009 y 0.016)
- Necesitamos crear nuevas variables y balancear clases

---

### **ARCHIVO #2: `stroke_preprocessing.ipynb`**

**¬øQu√© es?** Preprocesamiento de Datos

**¬øQu√© hace?**
- TRANSFORMAR los datos para que los modelos ML puedan aprender
- Crear 8 nuevas variables (feature engineering)
-  Eliminar variables in√∫tiles
-  Convertir texto a n√∫meros (encoding)
-  Dividir en Train/Validation/Test (60/20/20)
-  Normalizar con StandardScaler
-  **Balancear con SMOTE** (SOLO en Train)

**Resultado:** Datasets listos para entrenar modelos:
-  X_train_balanced.pkl (4,258 filas) ‚Üê **Balanceado con SMOTE**
-  X_val_scaled.pkl (996 filas) ‚Üê **SIN SMOTE**
-  X_test_scaled.pkl (997 filas) ‚Üê **SIN SMOTE**

---

## ANALOG√çA DEL ESTUDIANTE:

### **TRAIN = Material de Estudio (60%)**

Aqu√≠ **APRENDES**, puedes hacer lo que quieras para aprender mejor:

```
ANTES de SMOTE:
  Sin Stroke: 2,839 casos (95%)  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
  Con Stroke: 149 casos (5%)     ‚ñà

DESPU√âS de SMOTE:
  Sin Stroke: 2,839 casos (67%)  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
  Con Stroke: 1,419 casos (33%)  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
```

**¬øPor qu√© a√±adimos casos sint√©ticos?**
- El modelo necesita VER SUFICIENTES EJEMPLOS de ambas clases
- Con solo 149 casos de stroke, el modelo NO aprende bien
- SMOTE crea 1,270 casos sint√©ticos adicionales
- Ahora el modelo ve ~10x m√°s ejemplos de stroke y puede aprender a detectarlos

---

###  **VALIDATION

Aqu√≠ **EVAL√öAS** tu progreso antes del examen final:

```
Sin Stroke: 947 casos (95%)  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
Con Stroke: 49 casos (5%)    ‚ñà
```

**¬øPor qu√© NO a√±adimos casos sint√©ticos?**
- ‚ùå Queremos ver el rendimiento REAL
- ‚ùå Si a√±adimos datos falsos, nos enga√±amos
- ‚úÖ Mantenemos la distribuci√≥n REAL del mundo (95% vs 5%)
- ‚úÖ As√≠ sabemos si el modelo funcionar√° en la vida real

---

### **TEST = Examen Final (20%)**

Aqu√≠ **MIDES** el rendimiento final REAL:

```
Sin Stroke: 947 casos (95%)  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
Con Stroke: 50 casos (5%)    ‚ñà
```

**¬øPor qu√© NO a√±adimos casos sint√©ticos?**
- ‚ùå Es la evaluaci√≥n FINAL, debe ser 100% realista
- ‚ùå Los datos sint√©ticos distorsionar√≠an la medici√≥n
- ‚úÖ Evaluamos con la distribuci√≥n REAL del mundo
- ‚úÖ As√≠ sabemos el rendimiento VERDADERO que tendr√° con pacientes reales

---

## **¬øQU√â PASAR√çA SI US√ÅRAMOS SMOTE EN TODO?**

### ‚ùå **ESCENARIO ERR√ìNEO:**

```python
# ‚ùå MAL - NUNCA HACER ESTO
X_train_balanced = smote(X_train)   # ‚úÖ OK
X_val_balanced = smote(X_val)       # ‚ùå ERROR
X_test_balanced = smote(X_test)     # ‚ùå ERROR

# Resultado:
# - F1 en test: 0.85 ‚úÖ (PARECE GENIAL pero es MENTIRA)
# - En pacientes reales: F1 = 0.40 ‚ùå (DESASTRE)
```

**Problema:** Est√°s evaluando en datos FALSOS (sint√©ticos), no sabes c√≥mo funciona en la realidad.

---

### ‚úÖ **ESCENARIO CORRECTO:**

```python
# ‚úÖ BIEN - FORMA CORRECTA
X_train_balanced = smote(X_train)   # ‚úÖ Solo aqu√≠
# X_val NO se toca - distribuci√≥n real 95% vs 5%
# X_test NO se toca - distribuci√≥n real 95% vs 5%

# Resultado:
# - F1 en test: 0.70 ‚úÖ (REALISTA)
# - En pacientes reales: F1 = 0.70 ‚úÖ (COINCIDE)
```

**Beneficio:** Sabes EXACTAMENTE c√≥mo funcionar√° en la vida real.

---

## **RESUMEN EN 3 PUNTOS:**

1. **SMOTE es para ENTRENAR, no para EVALUAR**
   - ‚úÖ Uso: Solo en Train
   - ‚ùå NO usar: Validation ni Test

2. **Validation/Test deben ser REALES**
   - ‚úÖ Mantienen distribuci√≥n original (95% vs 5%)
   - ‚úÖ Reflejan c√≥mo ser√° en pacientes reales

3. **Si modificamos Validation/Test = TRAMPA**
   - ‚ùå Resultados artificialmente inflados
   - ‚ùå No sabemos el rendimiento real
   - ‚ùå Modelo fallar√° en producci√≥n

---

## **TABLA RESUMEN:**

| Conjunto | Tama√±o Original | Despu√©s SMOTE | ¬øPor qu√©? |
|----------|----------------|---------------|-----------|
| **TRAIN** | 2,988 (95% vs 5%) | 4,258 (67% vs 33%) | Para que el modelo APRENDA con ejemplos balanceados |
| **VALIDATION** | 996 (95% vs 5%) | 996 (95% vs 5%) | Para EVALUAR en condiciones reales |
| **TEST** | 997 (95% vs 5%) | 997 (95% vs 5%) | Para medir rendimiento FINAL en datos reales |

---

# RESUMEN DEL DATASET

## Dataset Original

- **Archivo:** `stroke_dataset.csv`
- **Tama√±o:** 4,981 pacientes √ó 11 variables
- **Calidad:** ‚úÖ Excelente (0% nulos, 0% duplicados)
- **Problema:** ‚ö†Ô∏è Desbalanceo SEVERO (19:1)

## Top 5 Variables M√°s Importantes

| # | Variable | Correlaci√≥n | Insight |
|---|----------|-------------|---------|
| ü•á | **age** | 0.246 | Edad promedio con stroke: **67.8 a√±os** vs sin stroke: **42.1 a√±os** |
| ü•à | **heart_disease** | 0.135 | Con enfermedad: **17%** stroke vs sin ella: **4%** |
| ü•â | **avg_glucose_level** | 0.133 | Con stroke: **132 mg/dL** vs sin stroke: **104 mg/dL** |
| 4Ô∏è‚É£ | **hypertension** | 0.132 | Con hipertensi√≥n: **14%** stroke vs sin ella: **4%** |
| 5Ô∏è‚É£ | **ever_married** | 0.108 | Casados: **7%** stroke vs solteros: **2%** |

## Variables Eliminadas (No sirven)

- ‚ùå **gender** (correlaci√≥n: 0.009) - No aporta informaci√≥n
- ‚ùå **Residence_type** (correlaci√≥n: 0.016) - No aporta informaci√≥n

## Features Creadas (Feature Engineering)

1. **age_group** - Categor√≠as: Child, Young_Adult, Adult, Senior
2. **glucose_category** - Normal, Prediabetes, Diabetes
3. **bmi_category** - Underweight, Normal, Overweight, Obese
4. **has_smoked** - Binaria: fum√≥ alguna vez (s√≠/no)
5. **risk_score** - Score compuesto de factores de riesgo
6. **age_x_hypertension** - Interacci√≥n edad √ó hipertensi√≥n
7. **age_x_heart_disease** - Interacci√≥n edad √ó enfermedad card√≠aca
8. **glucose_x_bmi** - Interacci√≥n glucosa √ó BMI

**Total Features Final:** 25 (de 11 originales)

## Archivos Generados

```
data/
‚îú‚îÄ‚îÄ X_train_balanced.pkl    # 4,258 √ó 25 (834 KB) - TRAIN balanceado
‚îú‚îÄ‚îÄ y_train_balanced.pkl    # 4,258 (34 KB)
‚îú‚îÄ‚îÄ X_val_scaled.pkl        # 996 √ó 25 (203 KB) - VALIDATION original
‚îú‚îÄ‚îÄ y_val.pkl               # 996 (24 KB)
‚îú‚îÄ‚îÄ X_test_scaled.pkl       # 997 √ó 25 (204 KB) - TEST original
‚îú‚îÄ‚îÄ y_test.pkl              # 997 (24 KB)
‚îî‚îÄ‚îÄ scaler.pkl              # StandardScaler (1.6 KB)
```

---

## ¬øPor qu√© hay 7 archivos separados y en formato .pkl?

### ¬øPor qu√© separar X (caracter√≠sticas) de y (target)?

**Regla fundamental de ML:**
> "Las caracter√≠sticas (X) se separan del objetivo (y) porque el modelo aprende de X para predecir y"

**Analog√≠a del examen:**
- **X** = Las PREGUNTAS del examen (edad, glucosa, BMI, etc.)
- **y** = Las RESPUESTAS correctas (stroke: 0 o 1)
- El modelo ve solo X y debe adivinar y
- Luego comparamos con las respuestas correctas

**Por eso hay 6 archivos:**
- X_train + y_train (entrenamiento)
- X_val + y_val (validaci√≥n)
- X_test + y_test (evaluaci√≥n final)

### ¬øQu√© es scaler.pkl?
- Es el objeto StandardScaler usado para normalizar los datos
- Guarda la media y desviaci√≥n est√°ndar de cada variable
- Necesario para normalizar nuevos datos en producci√≥n

### ** Explicaci√≥n detallada de cada archivo:**

#### ** X_train_balanced.pkl (Caracter√≠sticas de entrenamiento)**

**¬øQu√© contiene?**
- Las 25 variables (edad, glucosa, BMI, etc.) de cada paciente
- 4,258 filas (pacientes)
- **NO** incluye la columna `stroke`
- Tama√±o: 834 KB

**¬øPara qu√© sirve?**
- El modelo aprende de ESTAS caracter√≠sticas para predecir stroke
- Ya est√° balanceado con SMOTE (67% sin stroke, 33% con stroke)
- Ya est√° normalizado con StandardScaler

---

#### ** y_train_balanced.pkl (Target de entrenamiento)**

**¬øQu√© contiene?**
- SOLO la columna `stroke` (0 o 1)
- 4,258 valores
- Las "respuestas correctas" que el modelo debe aprender a predecir
- Tama√±o: 34 KB

**¬øPara qu√© sirve?**
- Es lo que el modelo intenta predecir
- Durante el entrenamiento, el modelo compara sus predicciones con estos valores
- Balanceado: 2,839 (0) + 1,419 (1) = ratio 2:1

---

#### ** X_val_scaled.pkl (Caracter√≠sticas de validaci√≥n)**

**¬øQu√© contiene?**
- Las 25 variables de 996 pacientes
- **NO** incluye `stroke`
- **SIN** SMOTE (distribuci√≥n real: 95% vs 5%)
- Tama√±o: 203 KB

**¬øPara qu√© sirve?**
- Evaluar el modelo durante el entrenamiento
- Ajustar hiperpar√°metros
- Ver si hay overfitting (comparando Train vs Validation)

---

#### ** y_val.pkl (Target de validaci√≥n)**

**¬øQu√© contiene?**
- SOLO `stroke` de esos 996 pacientes
- Distribuci√≥n real: 947 (0) + 49 (1) = ratio 19:1
- Tama√±o: 24 KB

**¬øPara qu√© sirve?**
- Comparar las predicciones del modelo con la realidad
- Calcular m√©tricas (F1, Recall, Precision, etc.)
- Medir rendimiento en datos reales (no balanceados)

---

#### ** X_test_scaled.pkl (Caracter√≠sticas de test)**

**¬øQu√© contiene?**
- Las 25 variables de 997 pacientes
- **NO** incluye `stroke`
- **SIN** SMOTE (distribuci√≥n real: 95% vs 5%)
- Tama√±o: 204 KB

**¬øPara qu√© sirve?**
- Evaluaci√≥n FINAL del modelo
- **NO** se usa durante el entrenamiento
- Solo se usa al final para medir el rendimiento verdadero

---

#### ** y_test.pkl (Target de test)**

**¬øQu√© contiene?**
- SOLO `stroke` de esos 997 pacientes
- Distribuci√≥n real: 947 (0) + 50 (1) = ratio 19:1
- Tama√±o: 24 KB

**¬øPara qu√© sirve?**
- Las respuestas correctas para la evaluaci√≥n final
- Se comparan con las predicciones del modelo entrenado
- Determina el rendimiento REAL en producci√≥n

---

#### ** scaler.pkl (Normalizador)**

**¬øQu√© contiene?**
- El objeto StandardScaler entrenado
- Guarda la media y desviaci√≥n est√°ndar de cada una de las 25 variables
- Tama√±o: 1.6 KB

**¬øPara qu√© sirve?**
- Para normalizar datos nuevos en producci√≥n
- Ejemplo: Si llega un nuevo paciente con edad=65, el scaler lo convierte a escala normalizada
- **CR√çTICO** para que el modelo funcione correctamente con datos nuevos
- Sin esto, el modelo recibir√≠a datos en escala diferente y fallar√≠a

### ** C√≥mo cargar los archivos:**

```python
import pickle
import pandas as pd

# Cargar datos de entrenamiento
X_train = pd.read_pickle('data/X_train_balanced.pkl')
y_train = pd.read_pickle('data/y_train_balanced.pkl')

# Cargar scaler
with open('data/scaler.pkl', 'rb') as f:
    scaler = pickle.load(f)

print(f"X_train shape: {X_train.shape}")  # (4258, 25)
print(f"y_train shape: {y_train.shape}")  # (4258,)
```

---

## C√≥mo desplegar y ejecutar este repositorio

### 1) Preparar entorno virtual (recomendado)

Abre una terminal (zsh) en la ra√≠z del repositorio y ejecuta:

```bash
# Crear entorno virtual (usa Python 3)
python3 -m venv .venv

# Activarlo (zsh)
source .venv/bin/activate

# Actualizar pip y instalar dependencias desde requirements.txt
pip install -U pip
pip install -r requirements.txt
```

### 2) Estructura de la carpeta `data` y archivos esperados

Antes de ejecutar los notebooks, la carpeta `data/` debe contener el archivo fuente original:

- `data/stroke_dataset.csv` ‚Üí el CSV original con las 11 columnas del dataset (4,981 filas).

Despu√©s de ejecutar el notebook de preprocesamiento (ver m√°s abajo), se generar√°n los archivos `.pkl` que el resto del flujo asume:

```
data/
‚îú‚îÄ‚îÄ X_train_balanced.pkl    # 4,258 √ó 25 (TRAIN balanceado con SMOTE)
‚îú‚îÄ‚îÄ y_train_balanced.pkl    # 4,258 (target train)
‚îú‚îÄ‚îÄ X_val_scaled.pkl        # 996 √ó 25 (VALIDATION sin SMOTE)
‚îú‚îÄ‚îÄ y_val.pkl               # 996 (target val)
‚îú‚îÄ‚îÄ X_test_scaled.pkl       # 997 √ó 25 (TEST sin SMOTE)
‚îú‚îÄ‚îÄ y_test.pkl              # 997 (target test)
‚îî‚îÄ‚îÄ scaler.pkl              # StandardScaler usado para normalizar
```


### 3) Orden recomendado para abrir/ejecutar los notebooks

1. `stroke_eda_complete.ipynb` (EDA)
    - Objetivo: entender el dataset, revisar distribuciones, correlaciones y decidir transformaciones.
    - Recomendaci√≥n: ejecutar celda por celda, revisar gr√°ficas y outputs. No deber√≠a modificar archivos en `data/` salvo que haya celdas expl√≠citas para guardado de artefactos.

2. `stroke_preprocessing.ipynb` (Preprocesamiento)
    - Objetivo: transformar el CSV original en los `.pkl` listados arriba.
    - Antes de ejecutar: aseg√∫rate de que `data/stroke_dataset.csv` est√° presente.
    - Recomendaci√≥n: ejecutar las celdas en orden. El notebook realiza:
       - Feature engineering (nuevas variables)
       - Encoding y limpieza
       - Divisi√≥n Train/Val/Test (60/20/20)
       - Escalado con StandardScaler
       - SMOTE solo en el conjunto de entrenamiento
       - Guardado de `X_*.pkl`, `y_*.pkl` y `scaler.pkl` en `data/`

3. Validaci√≥n / entrenamiento de modelos
    - Una vez generados los `.pkl`, puedes usar scripts o notebooks de modelado que carguen `data/X_train_balanced.pkl`, `data/y_train_balanced.pkl`, etc.

### 4) Comandos √∫tiles para abrir Jupyter

Con el entorno activado:

```bash
# Abrir Jupyter Lab (recomendado)
jupyter lab

# o abrir Jupyter Notebook
jupyter notebook
```

Abre los notebooks en el navegador y usa la opci√≥n "Run -> Run All Cells" si conf√≠as en el flujo; sino ejecuta celda a celda para inspeccionar resultados.

### 5) Verificaciones r√°pidas despu√©s del preprocesamiento

- Confirmar que `data/X_train_balanced.pkl` existe y tiene ~4258 filas.
- Confirmar que `data/X_val_scaled.pkl` y `data/X_test_scaled.pkl` existen y mantienen la distribuci√≥n original (‚âà95% sin stroke, ‚âà5% con stroke).
- Confirmar que `data/scaler.pkl` existe. Este archivo es necesario para normalizar datos nuevos en producci√≥n.

